{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy attack simulation with Iris dataset\n",
    "Authors : Johan Jublanc / Vincent Heng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_columns = iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dataset with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data = np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "x_a, x_b, y_a, y_b = train_test_split(x,y,test_size=.5)\n",
    "x_b1, x_b2, y_b1, y_b2 = train_test_split(x_b,y_b,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(x_b1,y_b1)\n",
    "\n",
    "y_pred=clf.predict(x_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_b2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(x_b,y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a shadow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get macro information about the dataset D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attacker have only few public information about the original train dataset. The information detained by the attacker is denoted $I$. Here the information is just the mean and standard deviation for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = data1.iloc[:,0:4]\n",
    "I = I.describe()\n",
    "I = I.loc[[(x in ['mean', 'std']) for x in I.index],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a simulation thanks to the model API (here clf) and use it to build up the shadow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_from_I(I):\n",
    "    d_s = []\n",
    "    for col in I.columns:\n",
    "        mean = I.loc[\"mean\",col]\n",
    "        std  = I.loc[\"std\",col]\n",
    "        d_s.append(np.random.normal(mean, std, 1)[0])\n",
    "    return d_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_a_point(clf, I, threshold=0.7) :\n",
    "    is_point_chosen = False\n",
    "    while not is_point_chosen :\n",
    "        d_s = get_sample_from_I(I)\n",
    "        is_point_chosen = (np.max(clf.predict_proba([d_s])) > threshold)\n",
    "    predicted_class = np.argmax(clf.predict_proba([d_s]))\n",
    "    return d_s, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_in_an_hypercube(d_f, I):\n",
    "    d_f_j = []\n",
    "    for i in range(len(d_f)):\n",
    "        mean = d_f[i]\n",
    "        std  = I.loc[\"std\", I.columns[i]]\n",
    "        d_f_j.append(np.random.uniform(mean - std/2, mean + std/2, 1)[0])\n",
    "    return d_f_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_D_prim(clf, I, threshold=0.7, total_size = 300, sample_by_hypercube = 10):\n",
    "    D_prim = []\n",
    "    \n",
    "    while len(D_prim) < total_size :\n",
    "        \n",
    "        # sample a point with a high for which the prediction is good\n",
    "        d_f, class_ = choose_a_point(clf, I, threshold)\n",
    "        D_prim.append(d_f + [class_])\n",
    "        \n",
    "        # sample in the hypercube\n",
    "        for i in range(sample_by_hypercube):\n",
    "            d_f_j = sample_in_an_hypercube(d_f, I)\n",
    "            predicted_class = np.argmax(clf.predict_proba([d_f_j]))\n",
    "            D_prim.append(d_f_j + [predicted_class])     \n",
    "    \n",
    "    D_prim = pd.DataFrame(data=D_prim,\n",
    "                          columns=(list(I.columns)+[\"label\"]))\n",
    "    return D_prim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_prim = generate_D_prim(clf, I, total_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of an attack model training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_prim_in, D_prim_out  = train_test_split(D_prim, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prim_out = D_prim_out.iloc[:,0:4]\n",
    "y_prim_out = D_prim_out.iloc[:,4]\n",
    "\n",
    "x_prim_in = D_prim_in.iloc[:,0:4]\n",
    "y_prim_in = D_prim_in.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_prim = RandomForestClassifier(n_estimators=100)\n",
    "clf_prim.fit(x_prim_in,y_prim_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_star_in = pd.DataFrame(clf_prim.predict_proba(x_prim_in), columns = (\"p_0\", \"p_1\", \"p_2\"))\n",
    "D_star_in[\"is_in\"] = 1\n",
    "\n",
    "D_star_out = pd.DataFrame(clf_prim.predict_proba(x_prim_out), columns = (\"p_0\", \"p_1\", \"p_2\"))\n",
    "D_star_out[\"is_in\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_star = pd.concat([D_star_in, D_star_out]).reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_col_star = len(D_star.columns)\n",
    "x_star = D_star.iloc[:, 0:(nb_col_star-1)]\n",
    "y_star = D_star.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_attack = RandomForestClassifier(n_estimators=100)\n",
    "clf_attack.fit(x_star,y_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the attack against the true data set D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = pd.DataFrame(x_a, columns=x_columns)\n",
    "x_b = pd.DataFrame(x_b, columns=x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_a   = pd.DataFrame(clf_prim.predict_proba(x_a), columns = (\"p_0\", \"p_1\", \"p_2\"))\n",
    "predict_a = clf_attack.predict(proba_a)\n",
    "result_a  = pd.DataFrame(zip(predict_a, [0 for i in range(len(proba_a))]), columns = (\"y_pred\", \"y\"))\n",
    "\n",
    "proba_b   = pd.DataFrame(clf_prim.predict_proba(x_b), columns = (\"p_0\", \"p_1\", \"p_2\"))\n",
    "predict_b = clf_attack.predict(proba_b)\n",
    "result_b  = pd.DataFrame(zip(predict_b, [1 for i in range(len(proba_b))]), columns = (\"y_pred\", \"y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack_results = pd.concat([result_a, result_b]).reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(attack_results[\"y\"], attack_results[\"y_pred\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
