{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership inference attack with images\n",
    "Authors : Johan Jublanc / Vincent Heng\n",
    "\n",
    "We use this article to simulate a membership inference attack : https://arxiv.org/pdf/1807.09173.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import tarfile\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (\"data\" in listdir()):\n",
    "    ! mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the CIFAR10 data which is a dataset of color images of size 32x32. For more information let's go here :\n",
    "- https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = \"./data/cifar10.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "urllib.request.urlretrieve(url, data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(data_file_name, \"r:gz\")\n",
    "tar.extractall(\"./data\")\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batches_names = [f for f in listdir(\"./data/cifar-10-batches-py\") if f.split(\"_\")[0:2]==[\"data\",\"batch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 data are splited in batches. For this example the first batche is used to build up a classifier and the second one will be used to build up the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = unpickle(\"./data/cifar-10-batches-py/\" + data_batches_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up a model to predict the category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly build a model that is trained on the dataset $data_b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=data[b\"data\"]\n",
    "y=data[b\"labels\"]\n",
    "x_a, x_b, y_a, y_b = train_test_split(x,y,test_size=.5)\n",
    "x_b1, x_b2, y_b1, y_b2 = train_test_split(x_b,y_b,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first model is trained on 80% of the $data_b$ and test on the 20% left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=400)\n",
    "clf.fit(x_b1,y_b1)\n",
    "y_pred=clf.predict(x_b2)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_b2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the model is train over the complete dataset $data_b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=400)\n",
    "clf.fit(x_b, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a shadow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information about the dataset D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the attacker knows another dataset that is similar to D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prim = unpickle(\"./data/cifar-10-batches-py/\" + data_batches_names[1])\n",
    "x_prim = data_prim[b\"data\"]\n",
    "y_prim = data_prim[b\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2805\n",
    "fig, axes = plt.subplots(1,1,figsize=(1.5,1.5))\n",
    "plt.imshow(np.reshape(data[b'data'][i],(3,32,32)).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of an attack model training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build up a classifier to reproduce the beheaviour of the original classifier, which for us is a blackbox. The main goal here is to be able to compute probabilities for both the \"in\" and \"out\" part of the dataset $D'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prim_in, x_prim_out, y_prim_in, y_prim_out = train_test_split(x_prim, \n",
    "                                                                y_prim,\n",
    "                                                                test_size=.5)\n",
    "\n",
    "x_prim_in_train, x_prim_in_test, y_prim_in_train, y_prim_in_test = train_test_split(x_prim_in, \n",
    "                                                                                    y_prim_in, \n",
    "                                                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_prim = RandomForestClassifier(n_estimators=400)\n",
    "clf_prim.fit(x_prim_in_train, y_prim_in_train)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_prim_in_test, clf_prim.predict(x_prim_in_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_prim = RandomForestClassifier(n_estimators=400)\n",
    "clf_prim.fit(x_prim_in, y_prim_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model on the \"in\" part of the data, we can make a prediction on both dataset's parts (\"in\" and \"out\") a labelise the results. The new dataset is named $D*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star_in = clf_prim.predict_proba(x_prim_in)\n",
    "y_star_in = [1 for i in range(len(x_star_in))]\n",
    "\n",
    "x_star_out = clf_prim.predict_proba(x_prim_out)\n",
    "y_star_out = [0 for i in range(len(x_star_out))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.concatenate([x_star_in, x_star_out], axis=0)\n",
    "y_star = np.concatenate([y_star_in, y_star_out], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the attack model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref : https://www.datacamp.com/community/tutorials/xgboost-in-python#apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star_train, x_star_test, y_star_train, y_star_test = train_test_split(x_star, y_star, test_size =.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_attack  = xgb.XGBClassifier(objective ='reg:squarederror',\n",
    "                                colsample_bytree = 0.3,\n",
    "                                learning_rate = 0.1,\n",
    "                                max_depth = 5,\n",
    "                                alpha = 10,\n",
    "                                n_estimators = 10)\n",
    "\n",
    "clf_attack.fit(x_star_train,y_star_train)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_star_test, clf_attack.predict(x_star_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_attack  = xgb.XGBClassifier(objective ='reg:squarederror',\n",
    "                                colsample_bytree = 0.3,\n",
    "                                learning_rate = 0.1,\n",
    "                                max_depth = 5,\n",
    "                                alpha = 10,\n",
    "                                n_estimators = 10)\n",
    "clf_attack.fit(x_star,y_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the attack against the true data set D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_labels(intial_model, attack_model, data, label):\n",
    "\n",
    "    # Information we have thanks to the API (original model)\n",
    "    proba   = clf.predict_proba(data)\n",
    "\n",
    "    # Model we have trained to make the attack\n",
    "    prediction = clf_attack.predict(proba)\n",
    "\n",
    "    # Results zipping prediction an true labels\n",
    "    result  = pd.DataFrame(zip(prediction, [label for i in range(len(proba))]), columns = (\"y_pred\", \"y\"))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for images out of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_a = get_predictions_and_labels(intial_model = clf, attack_model=clf_attack, data=x_a, label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for images in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b = get_predictions_and_labels(intial_model = clf, attack_model=clf_attack, data=x_b, label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack_results = pd.concat([results_a, results_b]).reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(attack_results[\"y\"], attack_results[\"y_pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this picture in the training dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the data in which we pick up the image has been used to train the model\n",
    "data = x_b\n",
    "\n",
    "# plot the image\n",
    "i = np.random.randint(0,len(x_b), 1)[0]\n",
    "fig, axs = plt.subplots(1,1,figsize=(1.5,1.5))\n",
    "plt.imshow(np.reshape(data[i],(3,32,32)).transpose(1,2,0))\n",
    "\n",
    "# We query the original model to get probabilities\n",
    "proba   = clf.predict_proba([data[i]])\n",
    "# Then we predict if the picture belong to the training data\n",
    "predict = clf_attack.predict(proba)\n",
    "\n",
    "if predict == 1:\n",
    "    title = \"We predict YES and we are right !\"\n",
    "else :\n",
    "    title = \"We predict NO but we are wrong (loooser;)\"\n",
    "\n",
    "plt.title(title, size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the data in which we pick up the image has not been used to train the model\n",
    "data = x_a\n",
    "\n",
    "# plot the image\n",
    "i = np.random.randint(0,len(x_b), 1)[0]\n",
    "fig, axs = plt.subplots(1,1,figsize=(1.5,1.5))\n",
    "plt.imshow(np.reshape(data[i],(3,32,32)).transpose(1,2,0))\n",
    "\n",
    "# We query the original model to get probabilities\n",
    "proba   = clf.predict_proba([data[i]])\n",
    "# Then we predict if the picture belong to the training data\n",
    "predict = clf_attack.predict(proba)\n",
    "\n",
    "if predict == 1:\n",
    "    title = \"We predict YES and we are wrong (looooser ;)\"\n",
    "else :\n",
    "    title = \"We predict No and we are right !\"\n",
    "\n",
    "plt.title(title, size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attack works well. One should keep in mind that the model being attacked is not a very good model and that in this particular case we had the opportunity to use a known shadow database ($D'$), but in many cases one would have to make a simulation of the shadow dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
